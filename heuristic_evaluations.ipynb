{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environments.medevac import MedevacDispatchingEnvironment, greedy_policy, random_policy\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ZONES = 6\n",
    "ALPHA = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MedevacDispatchingEnvironment(\n",
    "    map_config_file=\"environments\\\\configuration\\\\afghanistan\\\\v2\\\\map.csv\",\n",
    "    MTF_config_file=\"environments\\\\configuration\\\\afghanistan\\\\v2\\\\MTFs.csv\", \n",
    "    staging_area_config_file=\"environments\\\\configuration\\\\afghanistan\\\\v2\\\\staging_areas.csv\",\n",
    "    casualty_cluster_center_config_file=\"environments\\\\configuration\\\\afghanistan\\\\v2\\\\casualty_cluster_centers.csv\",\n",
    "    intensity_function_config_file=\"environments\\\\configuration\\\\afghanistan\\\\v2\\\\intensity_function_ranges_1.csv\",\n",
    "    num_zones=NUM_ZONES,\n",
    "    forecast_recency_bias=ALPHA,\n",
    "    verbose=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "def confinterval(data, alpha=0.05):\n",
    "    n = np.size(data) # number of data points\n",
    "    if n <= 1:\n",
    "        raise ValueError(\"At least 2 data points are required to calculate a confidence interval.\")\n",
    "    sample_std = np.std(data, ddof=1) # sample standard deviation (ddof=1)\n",
    "    se = sample_std / np.sqrt(n) # standard error\n",
    "    t_score = t.ppf(1 - alpha / 2, n - 1) \n",
    "    mean = np.mean(data)\n",
    "    halfwidth = t_score * se\n",
    "    return mean, halfwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_service_metrics_df(metrics):\n",
    "    data = []\n",
    "    # Flatten the metrics into rows\n",
    "    for mtf, precedences in metrics[\"avg_service_times\"].items():\n",
    "        for precedence in precedences.keys():\n",
    "            data.append({\n",
    "                \"MTF\": mtf,\n",
    "                \"Precedence\": precedence.to_string(),\n",
    "                \"avg_service_times\": metrics[\"avg_service_times\"][mtf][precedence],\n",
    "                \"total_num_requests_serviced\": metrics[\"total_num_requests_serviced\"][mtf][precedence],\n",
    "                \"num_requests_serviced_on_time\": metrics[\"num_requests_serviced_on_time\"][mtf][precedence],\n",
    "                \"percent_requests_serviced_on_time\": metrics[\"percent_requests_serviced_on_time\"][mtf][precedence],\n",
    "            })\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(policy_name, policy, num_reps, seed_mult, offset): \n",
    "    # Initialize test data structures\n",
    "    test_data = np.zeros((num_reps))\n",
    "    all_metrics = []\n",
    "    zone_metrics = []\n",
    "    staging_area_metrics = []\n",
    "\n",
    "    # Run num_reps replications per test\n",
    "    for rep in range(num_reps):\n",
    "        # initialize episode complete flag (i.e.,when system enters terminal state)\n",
    "        done = False\n",
    "        # initialize episode reward\n",
    "        Gtest = 0\n",
    "        # initialize the system by resetting the environment, obtain state var\n",
    "        state, info = env.reset(seed=int(seed_mult*1000+rep+offset))\n",
    "        while not(done):\n",
    "            action = policy(state, info)\n",
    "            # apply action and observe system information\n",
    "            state, reward, done, truncated, info = env.step(action)\n",
    "            # update episode cumulative reward\n",
    "            Gtest += reward\n",
    "        test_data[rep] = Gtest\n",
    "\n",
    "        # Get request manager service metrics\n",
    "        metrics = env.unwrapped.request_manager.get_service_metrics()\n",
    "        metrics_df = get_service_metrics_df(metrics)\n",
    "        metrics_df['rep'] = rep\n",
    "        metrics_df['MTF'] = metrics_df['MTF'].astype(str)  # Convert MTF to string\n",
    "        all_metrics.append(metrics_df)\n",
    "\n",
    "        # Collect staging area metrics per staging area\n",
    "        for staging_area in env.unwrapped.staging_areas:\n",
    "            sa_metrics = staging_area.get_service_metrics()\n",
    "            staging_area_metrics.append({\n",
    "                \"Staging Area\": str(staging_area),  # Convert staging area object to string\n",
    "                \"num_helicopters_serviced\": sa_metrics[\"num_helicopters_serviced\"]\n",
    "            })\n",
    "\n",
    "        # Get service metrics for each zone\n",
    "        for zone in env.unwrapped.zones:\n",
    "            zone_metrics_df = get_service_metrics_df(zone.get_service_metrics())\n",
    "            zone_metrics_df['rep'] = rep\n",
    "            zone_metrics_df['Zone'] = str(zone)  # Convert Zone object to string\n",
    "            zone_metrics.append(zone_metrics_df)\n",
    "\n",
    "    # Concatenate all collected metrics into DataFrames\n",
    "    all_metrics_df = pd.concat(all_metrics, ignore_index=True)\n",
    "    zone_metrics_df = pd.concat(zone_metrics, ignore_index=True)\n",
    "    staging_area_metrics_df = pd.DataFrame(staging_area_metrics)\n",
    "\n",
    "    # Compute weighted average function\n",
    "    def weighted_avg(series, weights):\n",
    "        return (series * weights).sum() / weights.sum() if weights.sum() > 0 else 0\n",
    "\n",
    "    # Compute weighted averages for request manager service metrics\n",
    "    weighted_avg_df = all_metrics_df.groupby(['MTF', 'Precedence']).agg(\n",
    "        avg_service_times=('avg_service_times', lambda x: weighted_avg(x, all_metrics_df.loc[x.index, 'total_num_requests_serviced'])),\n",
    "        total_num_requests_serviced=('total_num_requests_serviced', 'sum'),\n",
    "        num_requests_serviced_on_time=('num_requests_serviced_on_time', 'sum'),\n",
    "        percent_requests_serviced_on_time=('num_requests_serviced_on_time', \n",
    "            lambda x: 100 * x.sum() / all_metrics_df.loc[x.index, 'total_num_requests_serviced'].sum() \n",
    "            if all_metrics_df.loc[x.index, 'total_num_requests_serviced'].sum() > 0 else 0)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Compute weighted averages for zone service metrics\n",
    "    weighted_zone_avg_df = zone_metrics_df.groupby(['Zone', 'Precedence']).agg(\n",
    "        avg_service_times=('avg_service_times', lambda x: weighted_avg(x, zone_metrics_df.loc[x.index, 'total_num_requests_serviced'])),\n",
    "        total_num_requests_serviced=('total_num_requests_serviced', 'sum'),\n",
    "        num_requests_serviced_on_time=('num_requests_serviced_on_time', 'sum'),\n",
    "        percent_requests_serviced_on_time=('num_requests_serviced_on_time', \n",
    "            lambda x: 100 * x.sum() / zone_metrics_df.loc[x.index, 'total_num_requests_serviced'].sum() \n",
    "            if zone_metrics_df.loc[x.index, 'total_num_requests_serviced'].sum() > 0 else 0)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Aggregate helicopter servicing counts for each staging area\n",
    "    total_staging_area_metrics_df = staging_area_metrics_df.groupby('Staging Area', as_index=False).sum()\n",
    "\n",
    "    # Save results to CSV\n",
    "    weighted_avg_df.to_csv(f'{policy_name}_weighted_avg_service_metrics.csv', index=False)\n",
    "    weighted_zone_avg_df.to_csv(f'{policy_name}_weighted_zone_metrics.csv', index=False)\n",
    "    total_staging_area_metrics_df.to_csv(f'{policy_name}_staging_area_metrics.csv', index=False)\n",
    "\n",
    "    mean, hw = confinterval(test_data)\n",
    "    return mean, hw, weighted_avg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reps = 60\n",
    "seed_mult = 2\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1, hw1, weighted_avg_df1 = evaluate('zones6_myopic',greedy_policy, num_reps, seed_mult, offset)\n",
    "print(f\"Mean: {mean1}, Halfwidth: {hw1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.default_rng()\n",
    "# mean2, hw2 = evaluate(lambda state, info: random_policy(state, info, rng), num_reps, seed_mult, offset)\n",
    "# print(f\"Mean: {mean2}, Halfwidth: {hw2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medevac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
