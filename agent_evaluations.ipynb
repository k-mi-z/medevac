{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environments.medevac import MedevacDispatchingEnvironment\n",
    "from algorithms.ddqn import DQN\n",
    "from gymnasium.wrappers import FlattenObservation\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ZONES = 12\n",
    "ALPHA = 0.25\n",
    "policy_name = \"zones12_alpha025\"\n",
    "policy_net_path = Path(\"experiment_results\") / policy_name / \"superlative.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space dimensionality: 338\n",
      "Number of actions: 33\n"
     ]
    }
   ],
   "source": [
    "env = MedevacDispatchingEnvironment(\n",
    "    map_config_file=\"environments\\\\configuration\\\\afghanistan\\\\v2\\\\map.csv\",\n",
    "    MTF_config_file=\"environments\\\\configuration\\\\afghanistan\\\\v2\\\\MTFs.csv\", \n",
    "    staging_area_config_file=\"environments\\\\configuration\\\\afghanistan\\\\v2\\\\staging_areas.csv\",\n",
    "    casualty_cluster_center_config_file=\"environments\\\\configuration\\\\afghanistan\\\\v2\\\\casualty_cluster_centers.csv\",\n",
    "    intensity_function_config_file=\"environments\\\\configuration\\\\afghanistan\\\\v2\\\\intensity_function_ranges_1.csv\",\n",
    "    num_zones=NUM_ZONES,\n",
    "    forecast_recency_bias=ALPHA,\n",
    "    verbose=False\n",
    "    )\n",
    "\n",
    "env = FlattenObservation(env)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "print(f\"State space dimensionality: {state_dim}\")\n",
    "\n",
    "n_actions = env.action_space.n\n",
    "print(f\"Number of actions: {n_actions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=338, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=256, out_features=33, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_neurons = 256\n",
    "policy_net = DQN(state_dim, n_actions, n_neurons)\n",
    "from pathlib import Path\n",
    "policy_net_state_dict = torch.load(policy_net_path, weights_only=True)\n",
    "policy_net.load_state_dict(policy_net_state_dict)\n",
    "policy_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "def confinterval(data, alpha=0.05):\n",
    "    n = np.size(data) # number of data points\n",
    "    if n <= 1:\n",
    "        raise ValueError(\"At least 2 data points are required to calculate a confidence interval.\")\n",
    "    sample_std = np.std(data, ddof=1) # sample standard deviation (ddof=1)\n",
    "    se = sample_std / np.sqrt(n) # standard error\n",
    "    t_score = t.ppf(1 - alpha / 2, n - 1) \n",
    "    mean = np.mean(data)\n",
    "    halfwidth = t_score * se\n",
    "    return mean, halfwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(policy_net, rep, seed_mult, offset, is_constrained=True): \n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        cumulative_reward = 0\n",
    "        state, info = env.reset(seed=int(seed_mult * 1000 + rep + offset))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            while not(terminated or truncated):\n",
    "                \n",
    "                state_action_values = policy_net(\n",
    "                    torch.as_tensor(state, dtype=torch.float32, device=\"cpu\").unsqueeze(0)\n",
    "                    ).squeeze(0)\n",
    "\n",
    "                if is_constrained:\n",
    "                    mask = torch.tensor(info['mask'], dtype=torch.bool, device=\"cpu\")\n",
    "                    state_action_values[~mask] = float('-inf')\n",
    "                \n",
    "                action = state_action_values.argmax().item()\n",
    "\n",
    "                state, reward, terminated, truncated, info = env.step(action)\n",
    "                cumulative_reward += reward        \n",
    "\n",
    "        return cumulative_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_service_metrics_df(metrics):\n",
    "    data = []\n",
    "    # Flatten the metrics into rows\n",
    "    for mtf, precedences in metrics[\"avg_service_times\"].items():\n",
    "        for precedence in precedences.keys():\n",
    "            data.append({\n",
    "                \"MTF\": mtf,\n",
    "                \"Precedence\": precedence.to_string(),\n",
    "                \"avg_service_times\": metrics[\"avg_service_times\"][mtf][precedence],\n",
    "                \"total_num_requests_serviced\": metrics[\"total_num_requests_serviced\"][mtf][precedence],\n",
    "                \"num_requests_serviced_on_time\": metrics[\"num_requests_serviced_on_time\"][mtf][precedence],\n",
    "                \"percent_requests_serviced_on_time\": metrics[\"percent_requests_serviced_on_time\"][mtf][precedence],\n",
    "            })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def evaluate(policy_name, policy_net, num_reps, seed_mult, offset): \n",
    "    # Initialize test data structures\n",
    "    test_data = np.zeros((num_reps))\n",
    "    all_metrics = []\n",
    "    zone_metrics = []\n",
    "    staging_area_metrics = []\n",
    "\n",
    "    # Run num_reps replications per test\n",
    "    for rep in range(num_reps):\n",
    "        Gtest = evaluate_episode(policy_net, rep, seed_mult, offset)\n",
    "        test_data[rep] = Gtest\n",
    "\n",
    "        # Get request manager service metrics\n",
    "        metrics = env.unwrapped.request_manager.get_service_metrics()\n",
    "        metrics_df = get_service_metrics_df(metrics)\n",
    "        metrics_df['rep'] = rep\n",
    "        metrics_df['MTF'] = metrics_df['MTF'].astype(str)  # Convert MTF to string\n",
    "        all_metrics.append(metrics_df)\n",
    "\n",
    "        # Collect staging area metrics per staging area\n",
    "        for staging_area in env.unwrapped.staging_areas:\n",
    "            sa_metrics = staging_area.get_service_metrics()\n",
    "            staging_area_metrics.append({\n",
    "                \"Staging Area\": str(staging_area),  # Convert staging area object to string\n",
    "                \"num_helicopters_serviced\": sa_metrics[\"num_helicopters_serviced\"]\n",
    "            })\n",
    "\n",
    "        # Get service metrics for each zone\n",
    "        for zone in env.unwrapped.zones:\n",
    "            zone_metrics_df = get_service_metrics_df(zone.get_service_metrics())\n",
    "            zone_metrics_df['rep'] = rep\n",
    "            zone_metrics_df['Zone'] = str(zone)  # Convert Zone object to string\n",
    "            zone_metrics.append(zone_metrics_df)\n",
    "\n",
    "    # Concatenate all collected metrics into DataFrames\n",
    "    all_metrics_df = pd.concat(all_metrics, ignore_index=True)\n",
    "    zone_metrics_df = pd.concat(zone_metrics, ignore_index=True)\n",
    "    staging_area_metrics_df = pd.DataFrame(staging_area_metrics)\n",
    "\n",
    "    # Compute weighted average function\n",
    "    def weighted_avg(series, weights):\n",
    "        return (series * weights).sum() / weights.sum() if weights.sum() > 0 else 0\n",
    "\n",
    "    # Compute weighted averages for request manager service metrics\n",
    "    weighted_avg_df = all_metrics_df.groupby(['MTF', 'Precedence']).agg(\n",
    "        avg_service_times=('avg_service_times', lambda x: weighted_avg(x, all_metrics_df.loc[x.index, 'total_num_requests_serviced'])),\n",
    "        total_num_requests_serviced=('total_num_requests_serviced', 'sum'),\n",
    "        num_requests_serviced_on_time=('num_requests_serviced_on_time', 'sum'),\n",
    "        percent_requests_serviced_on_time=('num_requests_serviced_on_time', \n",
    "            lambda x: 100 * x.sum() / all_metrics_df.loc[x.index, 'total_num_requests_serviced'].sum() \n",
    "            if all_metrics_df.loc[x.index, 'total_num_requests_serviced'].sum() > 0 else 0)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Compute weighted averages for zone service metrics\n",
    "    weighted_zone_avg_df = zone_metrics_df.groupby(['Zone', 'Precedence']).agg(\n",
    "        avg_service_times=('avg_service_times', lambda x: weighted_avg(x, zone_metrics_df.loc[x.index, 'total_num_requests_serviced'])),\n",
    "        total_num_requests_serviced=('total_num_requests_serviced', 'sum'),\n",
    "        num_requests_serviced_on_time=('num_requests_serviced_on_time', 'sum'),\n",
    "        percent_requests_serviced_on_time=('num_requests_serviced_on_time', \n",
    "            lambda x: 100 * x.sum() / zone_metrics_df.loc[x.index, 'total_num_requests_serviced'].sum() \n",
    "            if zone_metrics_df.loc[x.index, 'total_num_requests_serviced'].sum() > 0 else 0)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Aggregate helicopter servicing counts for each staging area\n",
    "    total_staging_area_metrics_df = staging_area_metrics_df.groupby('Staging Area', as_index=False).sum()\n",
    "\n",
    "    # Save results to CSV\n",
    "    weighted_avg_df.to_csv(f'{policy_name}_weighted_avg_service_metrics.csv', index=False)\n",
    "    weighted_zone_avg_df.to_csv(f'{policy_name}_weighted_zone_metrics.csv', index=False)\n",
    "    total_staging_area_metrics_df.to_csv(f'{policy_name}_staging_area_metrics.csv', index=False)\n",
    "\n",
    "    mean, hw = confinterval(test_data)\n",
    "    return mean, hw, weighted_avg_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reps = 60\n",
    "seed_mult = 2\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 73.48338865679224, Halfwidth: 1.4759111332658597\n",
      "    MTF Precedence  avg_service_times  total_num_requests_serviced  \\\n",
      "0  MTF1   Priority           1.018242                          446   \n",
      "1  MTF1    Routine           1.201658                          414   \n",
      "2  MTF1     Urgent           2.505707                         2842   \n",
      "3  MTF2   Priority           1.412696                         5830   \n",
      "4  MTF2    Routine           1.878680                         2950   \n",
      "5  MTF2     Urgent           0.000000                            0   \n",
      "\n",
      "   num_requests_serviced_on_time  percent_requests_serviced_on_time  \n",
      "0                            446                         100.000000  \n",
      "1                            414                         100.000000  \n",
      "2                            716                          25.193526  \n",
      "3                           5748                          98.593482  \n",
      "4                           2950                         100.000000  \n",
      "5                              0                           0.000000  \n"
     ]
    }
   ],
   "source": [
    "mean, hw, weighted_avg_df = evaluate(policy_name,policy_net, num_reps, seed_mult, offset)\n",
    "print(f\"Mean: {mean}, Halfwidth: {hw}\")\n",
    "print(weighted_avg_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medevac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
